import streamlit as st
import requests
import json
from typing import Dict, Any
import pandas as pd

# íŽ˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ë¬¸ì„œ ê²€í†  ì„œë¹„ìŠ¤",
    page_icon="ðŸ“„",
    layout="wide"
)

# API ì„œë²„ URL
API_BASE_URL = "http://localhost:8000"

@st.cache_data(ttl=30)  # 30ì´ˆ ìºì‹œ
def get_config_status():
    """ë°±ì—”ë“œì—ì„œ ì„¤ì • ìƒíƒœë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    try:
        response = requests.get(f"{API_BASE_URL}/config/status")
        if response.status_code == 200:
            return response.json()
        else:
            return None
    except:
        return None

def main():
    st.title("ðŸ“„ ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì›Œë“œ ë¬¸ì„œ ê²€í†  ì„œë¹„ìŠ¤")
    st.markdown("ì›Œë“œ ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ì—¬ êµ¬ë¬¸ ì˜¤ë¥˜, ë§žì¶¤ë²•, ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ ê²€í† í•˜ì„¸ìš”.")
    
    # ì„¤ì • ìƒíƒœ í™•ì¸
    config_status = get_config_status()
    
    # ì‚¬ì´ë“œë°”
    with st.sidebar:
        st.header("ðŸ“‹ ê²€í†  í•­ëª©")
        st.markdown("""
        - **êµ¬ë¬¸ ì˜¤ë¥˜**: ê´„í˜¸, ë”°ì˜´í‘œ, ë¬¸ìž¥ë¶€í˜¸ ê²€ì‚¬
        - **ë§žì¶¤ë²•**: í•œêµ­ì–´/ì˜ì–´ ë§žì¶¤ë²• ë° ë„ì–´ì“°ê¸°
        - **ìŠ¤íƒ€ì¼ ì¼ê´€ì„±**: ì œëª© ìŠ¤íƒ€ì¼, í°íŠ¸ ì¼ê´€ì„±
        - **ë¬¸ì„œ êµ¬ì¡°**: ëª©ì°¨ êµ¬ì¡° ë° ì „ì²´ì ì¸ ë¬¸ì„œ êµ¬ì„±
        """)
        
        st.header("âš ï¸ ì£¼ì˜ì‚¬í•­")
        st.markdown("""
        - **.docx íŒŒì¼ë§Œ ì§€ì›**ë©ë‹ˆë‹¤
        - .doc íŒŒì¼ì€ ë¨¼ì € .docxë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”
        - Gitì´ ì„¤ì¹˜ë˜ì–´ ìžˆì–´ì•¼ í•œêµ­ì–´ íŒ¨í‚¤ì§€ê°€ ì •ìƒ ìž‘ë™í•©ë‹ˆë‹¤
        """)
        
        # ì„¤ì • ìƒíƒœ í‘œì‹œ
        if config_status:
            st.header("âš™ï¸ í˜„ìž¬ ì„¤ì • ìƒíƒœ")
            status_emoji = "âœ…" if config_status.get("analysis_enabled", True) else "âŒ"
            st.write(f"{status_emoji} ì „ì²´ ë¶„ì„: {'í™œì„±í™”' if config_status.get('analysis_enabled', True) else 'ë¹„í™œì„±í™”'}")
            
            st.write("**ì„¸ë¶€ ê¸°ëŠ¥:**")
            st.write(f"{'âœ…' if config_status.get('syntax_errors_enabled', True) else 'âŒ'} êµ¬ë¬¸ ì˜¤ë¥˜ ê²€ì‚¬")
            st.write(f"{'âœ…' if config_status.get('spelling_errors_enabled', True) else 'âŒ'} ë§žì¶¤ë²• ê²€ì‚¬")
            st.write(f"{'âœ…' if config_status.get('style_consistency_enabled', True) else 'âŒ'} ìŠ¤íƒ€ì¼ ì¼ê´€ì„±")
            st.write(f"{'âœ…' if config_status.get('document_structure_enabled', True) else 'âŒ'} ë¬¸ì„œ êµ¬ì¡°")
            
            if st.button("ðŸ”„ ì„¤ì • ìƒˆë¡œê³ ì¹¨"):
                st.experimental_rerun()
    
    # íŒŒì¼ ì—…ë¡œë“œ
    uploaded_file = st.file_uploader(
        "ì›Œë“œ ë¬¸ì„œë¥¼ ì„ íƒí•˜ì„¸ìš” (.docxë§Œ ì§€ì›)",
        type=['docx'],
        help="ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì›Œë“œ .docx í˜•ì‹ë§Œ ì§€ì›ë©ë‹ˆë‹¤. .doc íŒŒì¼ì€ ë¨¼ì € .docxë¡œ ë³€í™˜í•´ì£¼ì„¸ìš”."
    )
    
    if uploaded_file is not None:
        # íŒŒì¼ ì •ë³´ í‘œì‹œ
        st.success(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
        
        # ë¶„ì„ ë²„íŠ¼
        if st.button("ðŸ“Š ë¬¸ì„œ ë¶„ì„ ì‹œìž‘", type="primary"):
            with st.spinner("ë¬¸ì„œë¥¼ ë¶„ì„í•˜ê³  ìžˆìŠµë‹ˆë‹¤..."):
                try:
                    # API í˜¸ì¶œ
                    files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                    response = requests.post(f"{API_BASE_URL}/analyze-document/", files=files)
                    
                    if response.status_code == 200:
                        analysis_result = response.json()
                        display_analysis_results(analysis_result)
                    else:
                        st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {response.text}")
                        
                except requests.exceptions.ConnectionError:
                    st.error("API ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë°±ì—”ë“œ ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

def display_analysis_results(result: Dict[str, Any]):
    """ë¶„ì„ ê²°ê³¼ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    
    # ë¶„ì„ ì„¤ì • ì •ë³´ í‘œì‹œ
    if "analysis_config" in result:
        with st.expander("âš™ï¸ ë¶„ì„ ì„¤ì • ì •ë³´"):
            config_info = result["analysis_config"]
            col1, col2 = st.columns(2)
            with col1:
                st.write(f"êµ¬ë¬¸ ì˜¤ë¥˜ ê²€ì‚¬: {'âœ…' if config_info.get('syntax_enabled', True) else 'âŒ'}")
                st.write(f"ë§žì¶¤ë²• ê²€ì‚¬: {'âœ…' if config_info.get('spelling_enabled', True) else 'âŒ'}")
            with col2:
                st.write(f"ìŠ¤íƒ€ì¼ ì¼ê´€ì„±: {'âœ…' if config_info.get('style_enabled', True) else 'âŒ'}")
                st.write(f"ë¬¸ì„œ êµ¬ì¡°: {'âœ…' if config_info.get('structure_enabled', True) else 'âŒ'}")
            
            if "analysis_time" in result:
                st.write(f"ë¶„ì„ ì†Œìš” ì‹œê°„: {result['analysis_time']:.2f}ì´ˆ")
    
    # ì „ì²´ ìš”ì•½
    st.header("ðŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        syntax_errors = len(result["syntax_errors"])
        st.metric("êµ¬ë¬¸ ì˜¤ë¥˜", syntax_errors, delta=None if syntax_errors == 0 else f"-{syntax_errors}")
    
    with col2:
        total_spelling = (
            len(result["spelling_errors"]["korean"]) +
            len(result["spelling_errors"]["english"]) +
            len(result["spelling_errors"]["spacing"])
        )
        st.metric("ë§žì¶¤ë²• ì˜¤ë¥˜", total_spelling, delta=None if total_spelling == 0 else f"-{total_spelling}")
    
    with col3:
        toc_valid = result["style_consistency"]["toc_structure"]["valid"]
        st.metric("ëª©ì°¨ êµ¬ì¡°", "ì •ìƒ" if toc_valid else "ë¬¸ì œ", delta="âœ…" if toc_valid else "âŒ")
    
    with col4:
        total_chars = result["statistics"]["total_characters"]
        st.metric("ì´ ë¬¸ìž ìˆ˜", f"{total_chars:,}")
    
    # ì¶”ì²œì‚¬í•­
    st.header("ðŸ’¡ ì¶”ì²œì‚¬í•­")
    for i, recommendation in enumerate(result["recommendations"], 1):
        st.info(f"{i}. {recommendation}")
    
    # íƒ­ìœ¼ë¡œ ìƒì„¸ ê²°ê³¼ í‘œì‹œ
    tab1, tab2, tab3, tab4, tab5 = st.tabs(["êµ¬ë¬¸ ì˜¤ë¥˜", "ë§žì¶¤ë²• ê²€ì‚¬", "ìŠ¤íƒ€ì¼ ì¼ê´€ì„±", "ë¬¸ì„œ êµ¬ì¡°", "í†µê³„"])
    
    with tab1:
        display_syntax_errors(result["syntax_errors"])
    
    with tab2:
        display_spelling_errors(result["spelling_errors"])
    
    with tab3:
        display_style_consistency(result["style_consistency"])
    
    with tab4:
        display_document_structure(result["document_structure"])
    
    with tab5:
        display_statistics(result["statistics"])

def display_syntax_errors(syntax_errors):
    """êµ¬ë¬¸ ì˜¤ë¥˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("ðŸ” êµ¬ë¬¸ ì˜¤ë¥˜ ê²€ì‚¬ ê²°ê³¼")
    
    if not syntax_errors:
        st.success("êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! âœ…")
        return
    
    st.warning(f"ì´ {len(syntax_errors)}ê°œì˜ êµ¬ë¬¸ ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    for i, error in enumerate(syntax_errors, 1):
        with st.expander(f"ì˜¤ë¥˜ {i}: {error['type']} (ë¬¸ë‹¨ {error['paragraph']})"):
            st.write(f"**ì„¤ëª…**: {error['description']}")
            st.code(error['text'], language=None)

def display_spelling_errors(spelling_errors):
    """ë§žì¶¤ë²• ì˜¤ë¥˜ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("âœï¸ ë§žì¶¤ë²• ê²€ì‚¬ ê²°ê³¼")
    
    # í•œêµ­ì–´ ë§žì¶¤ë²•
    st.write("### í•œêµ­ì–´ ë§žì¶¤ë²•")
    if spelling_errors["korean"]:
        for error in spelling_errors["korean"]:
            with st.expander(f"ë¬¸ë‹¨ {error['paragraph']}: {error['original']} â†’ {error['suggestion']}"):
                st.code(error['context'], language=None)
    else:
        st.success("í•œêµ­ì–´ ë§žì¶¤ë²• ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ì˜ì–´ ë§žì¶¤ë²•
    st.write("### ì˜ì–´ ë§žì¶¤ë²•")
    if spelling_errors["english"]:
        for error in spelling_errors["english"]:
            suggestions = ", ".join(error['suggestions']) if error['suggestions'] else "ì œì•ˆ ì—†ìŒ"
            with st.expander(f"ë¬¸ë‹¨ {error['paragraph']}: {error['word']} â†’ {suggestions}"):
                st.code(error['context'], language=None)
    else:
        st.success("ì˜ì–´ ë§žì¶¤ë²• ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ë„ì–´ì“°ê¸°
    st.write("### ë„ì–´ì“°ê¸°")
    if spelling_errors["spacing"]:
        for error in spelling_errors["spacing"]:
            with st.expander(f"ë¬¸ë‹¨ {error['paragraph']}: ë„ì–´ì“°ê¸° êµì • ì œì•ˆ"):
                st.write("**ì›ë³¸:**")
                st.code(error['original'], language=None)
                st.write("**êµì •:**")
                st.code(error['corrected'], language=None)
    else:
        st.success("ë„ì–´ì“°ê¸° ì˜¤ë¥˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_style_consistency(style_consistency):
    """ìŠ¤íƒ€ì¼ ì¼ê´€ì„±ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("ðŸŽ¨ ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ê²€ì‚¬")
    
    # ì œëª© êµ¬ì¡°
    st.write("### ì œëª© êµ¬ì¡°")
    headings = style_consistency["headings"]
    if headings:
        df_headings = pd.DataFrame(headings)
        st.dataframe(df_headings, use_container_width=True)
        
        # ëª©ì°¨ êµ¬ì¡° ê²€ì¦
        toc = style_consistency["toc_structure"]
        if toc["valid"]:
            st.success("ëª©ì°¨ êµ¬ì¡°ê°€ ì˜¬ë°”ë¦…ë‹ˆë‹¤! âœ…")
        else:
            st.warning("ëª©ì°¨ êµ¬ì¡°ì— ë¬¸ì œê°€ ìžˆìŠµë‹ˆë‹¤:")
            for issue in toc["issues"]:
                st.write(f"- {issue['description']}")
    else:
        st.info("ì œëª©ì´ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    # í°íŠ¸ ì¼ê´€ì„±
    st.write("### í°íŠ¸ ì‚¬ìš© í˜„í™©")
    font_info = style_consistency["font_consistency"]
    
    col1, col2 = st.columns(2)
    with col1:
        st.write("**ì‚¬ìš©ëœ í°íŠ¸:**")
        if font_info["fonts_used"]:
            for font, count in font_info["fonts_used"].items():
                st.write(f"- {font}: {count}íšŒ")
        else:
            st.write("í°íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    with col2:
        st.write("**ì‚¬ìš©ëœ í°íŠ¸ í¬ê¸°:**")
        if font_info["font_sizes_used"]:
            for size, count in font_info["font_sizes_used"].items():
                st.write(f"- {size}: {count}íšŒ")
        else:
            st.write("í°íŠ¸ í¬ê¸° ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def display_document_structure(structure):
    """ë¬¸ì„œ êµ¬ì¡°ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("ðŸ“‹ ë¬¸ì„œ êµ¬ì¡° ë¶„ì„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("ì „ì²´ ë¬¸ë‹¨ ìˆ˜", structure["total_paragraphs"])
        st.metric("ë‚´ìš©ì´ ìžˆëŠ” ë¬¸ë‹¨", structure["non_empty_paragraphs"])
        st.metric("ë¹ˆ ë¬¸ë‹¨", structure["empty_paragraphs"])
    
    with col2:
        st.metric("í‘œ ê°œìˆ˜", structure["table_count"])
        st.metric("ì¶”ì • ì´ë¯¸ì§€ ê°œìˆ˜", structure["estimated_image_count"])
    
    # ë¬¸ë‹¨ ë¹„ìœ¨ ì°¨íŠ¸
    if structure["total_paragraphs"] > 0:
        empty_ratio = structure["empty_paragraphs"] / structure["total_paragraphs"] * 100
        st.write(f"ë¹ˆ ë¬¸ë‹¨ ë¹„ìœ¨: {empty_ratio:.1f}%")
        
        if empty_ratio > 30:
            st.warning("ë¹ˆ ë¬¸ë‹¨ì´ ë„ˆë¬´ ë§ŽìŠµë‹ˆë‹¤. ë¬¸ì„œ ì •ë¦¬ë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤.")

def display_statistics(statistics):
    """ë¬¸ì„œ í†µê³„ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("ðŸ“ˆ ë¬¸ì„œ í†µê³„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.metric("í•œêµ­ì–´ ê¸€ìž ìˆ˜", f"{statistics['korean_characters']:,}")
        st.metric("ì˜ì–´ ë‹¨ì–´ ìˆ˜", f"{statistics['english_words']:,}")
        st.metric("ì´ ë¬¸ìž ìˆ˜", f"{statistics['total_characters']:,}")
    
    with col2:
        st.metric("ë¬¸ìž¥ ìˆ˜", f"{statistics['sentences']:,}")
        st.metric("ì˜ˆìƒ ì½ê¸° ì‹œê°„", f"{statistics['estimated_reading_time_minutes']}ë¶„")
    
    # ë¬¸ì„œ êµ¬ì„± ë¹„ìœ¨
    if statistics['total_characters'] > 0:
        korean_ratio = statistics['korean_characters'] / statistics['total_characters'] * 100
        st.write(f"í•œêµ­ì–´ ë¹„ìœ¨: {korean_ratio:.1f}%")

if __name__ == "__main__":
    main()